{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESULT</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if that’s the way u feel. That’s the way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>I‘m going to try for 2 months ha ha only joking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So ü pay first lar... Then when is da stock co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5510</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeah it's jus rite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511</th>\n",
       "      <td>ham</td>\n",
       "      <td>Armand says get your ass over to epsilon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5512</th>\n",
       "      <td>ham</td>\n",
       "      <td>U still havent got urself a jacket ah?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm taking derek &amp;amp; taylor to walmart, if I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi its in durban are you still on this number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5515</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ic. There are a lotta childporn cars then.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5516</th>\n",
       "      <td>ham</td>\n",
       "      <td>No, I was trying it all weekend ;V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517</th>\n",
       "      <td>ham</td>\n",
       "      <td>You know, wot people wear. T shirts, jumpers, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5518</th>\n",
       "      <td>ham</td>\n",
       "      <td>Cool, what time you think you can get here?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5519</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wen did you get so spiritual and deep. That's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>ham</td>\n",
       "      <td>Have a safe trip to Nigeria. Wish you happines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5521</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5522</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well keep in mind I've only got enough gas for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeh. Indians was nice. Tho it did kane me off ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5524</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5525</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. I meant the calculation is the same. That ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5526</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5527</th>\n",
       "      <td>ham</td>\n",
       "      <td>if you aren't here in the next  &amp;lt;#&amp;gt;  hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5528</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor. Juz both of us lor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>ham</td>\n",
       "      <td>Get me out of this dump heap. My mom decided t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5530</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ard 6 like dat lor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why don't you wait 'til at least wednesday to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5533</th>\n",
       "      <td>ham</td>\n",
       "      <td>Huh y lei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5534</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5540 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     RESULT                                                SMS\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5      spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6       ham  Even my brother is not like to speak with me. ...\n",
       "7       ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8      spam  WINNER!! As a valued network customer you have...\n",
       "9      spam  Had your mobile 11 months or more? U R entitle...\n",
       "10      ham  I'm gonna be home soon and i don't want to tal...\n",
       "11     spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12     spam  URGENT! You have won a 1 week FREE membership ...\n",
       "13      ham  I've been searching for the right words to tha...\n",
       "14      ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15     spam  XXXMobileMovieClub: To use your credit, click ...\n",
       "16      ham                         Oh k...i'm watching here:)\n",
       "17      ham  Eh u remember how 2 spell his name... Yes i di...\n",
       "18      ham  Fine if that’s the way u feel. That’s the way ...\n",
       "19     spam  England v Macedonia - dont miss the goals/team...\n",
       "20      ham          Is that seriously how you spell his name?\n",
       "21      ham    I‘m going to try for 2 months ha ha only joking\n",
       "22      ham  So ü pay first lar... Then when is da stock co...\n",
       "23      ham  Aft i finish my lunch then i go str down lor. ...\n",
       "24      ham  Ffffffffff. Alright no way I can meet up with ...\n",
       "25      ham  Just forced myself to eat a slice. I'm really ...\n",
       "26      ham                     Lol your always so convincing.\n",
       "27      ham  Did you catch the bus ? Are you frying an egg ...\n",
       "28      ham  I'm back &amp; we're packing the car now, I'll...\n",
       "29      ham  Ahhh. Work. I vaguely remember that! What does...\n",
       "...     ...                                                ...\n",
       "5510    ham                              Yeah it's jus rite...\n",
       "5511    ham           Armand says get your ass over to epsilon\n",
       "5512    ham             U still havent got urself a jacket ah?\n",
       "5513    ham  I'm taking derek &amp; taylor to walmart, if I...\n",
       "5514    ham      Hi its in durban are you still on this number\n",
       "5515    ham         Ic. There are a lotta childporn cars then.\n",
       "5516    ham                 No, I was trying it all weekend ;V\n",
       "5517    ham  You know, wot people wear. T shirts, jumpers, ...\n",
       "5518    ham        Cool, what time you think you can get here?\n",
       "5519    ham  Wen did you get so spiritual and deep. That's ...\n",
       "5520    ham  Have a safe trip to Nigeria. Wish you happines...\n",
       "5521    ham                        Hahaha..use your brain dear\n",
       "5522    ham  Well keep in mind I've only got enough gas for...\n",
       "5523    ham  Yeh. Indians was nice. Tho it did kane me off ...\n",
       "5524    ham  Yes i have. So that's why u texted. Pshew...mi...\n",
       "5525    ham  No. I meant the calculation is the same. That ...\n",
       "5526    ham                             Sorry, I'll call later\n",
       "5527    ham  if you aren't here in the next  &lt;#&gt;  hou...\n",
       "5528    ham                  Anything lor. Juz both of us lor.\n",
       "5529    ham  Get me out of this dump heap. My mom decided t...\n",
       "5530    ham  Ok lor... Sony ericsson salesman... I ask shuh...\n",
       "5531    ham                                Ard 6 like dat lor.\n",
       "5532    ham  Why don't you wait 'til at least wednesday to ...\n",
       "5533    ham                                       Huh y lei...\n",
       "5534   spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5535   spam  This is the 2nd time we have tried 2 contact u...\n",
       "5536    ham               Will ü b going to esplanade fr home?\n",
       "5537    ham  Pity, * was in mood for that. So...any other s...\n",
       "5538    ham  The guy did some bitching but I acted like i'd...\n",
       "5539    ham                         Rofl. Its true to its name\n",
       "\n",
       "[5540 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NaN because they are in the target variable.\n",
    "# We have to predict unlabeled so I saved them in another df\n",
    "\n",
    "df=pd.read_csv(\"sms.csv\",encoding='cp1252').drop(\"No\",axis=1)\n",
    "unlabeled=df[['RESULT','SMS']].fillna('unlabeled')\n",
    "unlabeled=unlabeled[unlabeled['RESULT']=='unlabeled']\n",
    "df=df.dropna().reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: ['ham' 'spam']\n",
      "%ham: 0.8664259927797834\n",
      "%spam: 0.13357400722021662\n"
     ]
    }
   ],
   "source": [
    "print('classes: '+str(df['RESULT'].unique()))\n",
    "print('%ham: '+str(len(df[df['RESULT']=='ham'])/len(df)))\n",
    "print('%spam: '+str(len(df[df['RESULT']=='spam'])/len(df)))\n",
    "\n",
    "# Dataset is unbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a class for cleaning and vectorizing textual data. I have helped \n",
    "# the owner to insert new things in my last job.\n",
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "#import spacy\n",
    "\n",
    "\n",
    "class text_preprocessing():\n",
    "    \"\"\" This class the preprocessing of a documents (text field) that are contained into a pandas DataFrame.\n",
    "        It's possible to perform the following step:\n",
    "            1. Text standardization with data cleaning (removal of special characters, numbers, link etc.).\n",
    "            2. Removal of stopwords.\n",
    "            3. Lemmatization.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        lemmatization (boolean) >>> Set it to True if you want to perform the lemmatization step.\n",
    "                                    Defalt is equal to False.\n",
    "        standardize (boolean)   >>> Set it to True if you want to perform the standardization step.\n",
    "                                    Defalt is equal to True.\n",
    "        chr_to_remove (list)    >>> List of strings (regex) that represent the vector of special char or string that\n",
    "                                    you want to remove.\n",
    "        chr_to_keep (regex)    >>> regex that represent the char that you want to keep. By default this method return \n",
    "                                   only the letters of english alphabet. If you want to keep another special character \n",
    "                                   you can specify this by setting this field. \n",
    "        language  (string)      >>> Optional. Language of the text that you want to analyze.\n",
    "                                    Default is 'en' (English).\n",
    "    \"\"\"\n",
    "     \n",
    "    def __init__(self, lemmatization = False, \n",
    "                standardize = True,\n",
    "                stopwords = True,\n",
    "                chr_to_remove = [r\"http\\S+\", r\"http\", r\"@\\S+\", r\"@\", r\"\"],\n",
    "                chr_to_keep = r\"[^A-Za-z]\",\n",
    "                language = 'en'):\n",
    "        \n",
    "        self.lemmatization = lemmatization\n",
    "        self.stopwords = stopwords\n",
    "        self.standardize = standardize\n",
    "        self.chr_to_remove = chr_to_remove\n",
    "        self.chr_to_keep = chr_to_keep\n",
    "        self.language = language\n",
    "\n",
    "    def is_null(self, text):\n",
    "        return text.isspace()\n",
    "\n",
    "    def standardize_text(self, df, text_field):\n",
    "\n",
    "        for regexp in self.chr_to_remove:\n",
    "            df[text_field] = df[text_field].str.replace(regexp, \"\")\n",
    "\n",
    "        df[text_field] = df[text_field].str.replace(self.chr_to_keep, \" \") #we not consider numbers \n",
    "        df[text_field] = df[text_field].str.lower()\n",
    "        return df\n",
    "\n",
    "    def remove_stopwords(self, text, stopwords):\n",
    "        clearlist = [word for word in text if word not in stopwords]\n",
    "        return clearlist\n",
    "    '''\n",
    "    def lemmatizer(self, text):\n",
    "        if self.language == 'it':\n",
    "            nlp = spacy.load('it_core_news_sm')\n",
    "        else:\n",
    "            nlp = spacy.load(self.language)\n",
    "        sent = []\n",
    "        doc = nlp(\" \".join(text))\n",
    "        for word in doc:\n",
    "            sent.append(word.lemma_)\n",
    "        return sent\n",
    "    '''\n",
    "    def fit(self, data_df, field):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        -----\n",
    "            data_df (pandas.DataFrame) >>> dataframe that contains the documents and the text field to process.\n",
    "            field (string) >>> name of the field (column) that contain the text to process.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            pandas.DataFrame that are the copy of the original dataframe plus a column that contain the clean tokens\n",
    "            (\"tokens\") and (if computed) another field with the lemma of these tokens (\"lemma\").\n",
    "        \"\"\"\n",
    "\n",
    "        # Drop fields which contain only space char\n",
    "        print(\"Data cleaning...\")\n",
    "        df = data_df[~data_df[field].apply(self.is_null)]\n",
    "\n",
    "        # Standardization\n",
    "        if self.standardize:\n",
    "            print(\"Standardization...\")\n",
    "            df = self.standardize_text(df, field)\n",
    "\n",
    "        # Token extraction\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        print(\"Tokenization...\")\n",
    "        df[\"tokens\"] = df[field].apply(tokenizer.tokenize)\n",
    "\n",
    "        # Stopwords\n",
    "        if self.stopwords:\n",
    "            if self.language == 'en':\n",
    "                stoplist = stopwords.words('english')\n",
    "            elif self.language == 'it':\n",
    "                stoplist = stopwords.words('italian')\n",
    "            else:\n",
    "                raise Exception(\"Invalid language\")\n",
    "            print(\"Removing stopwords...\")\n",
    "            df[\"tokens\"] = df[\"tokens\"].apply(self.remove_stopwords, stopwords=stoplist)\n",
    "\n",
    "        # Lemmatization\n",
    "        if self.lemmatization:\n",
    "            print(\"Lemmatization...\")\n",
    "            df[\"lemma\"] = df[\"tokens\"].apply(self.lemmatizer)\n",
    "        print(\"Finish\")\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "class vectorize_data():\n",
    "\n",
    "    \"\"\" This class compute the vectorization of a list of text tokens.\n",
    "    Args:\n",
    "    -----\n",
    "        method (string) >>> The metric used to transform the feature data. The choices are \"binary\", \"tf\" or \"tf-idf\".\n",
    "                            Default is \"tf-idf\".\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, method='tf-idf'):\n",
    "        self.method = method\n",
    "\n",
    "    def fit(self, train_data, test_data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        -----\n",
    "            train_data (pandas.Series) >>> column of the training set dataframe that contains the tokens to process.\n",
    "            test_data (pandas.Series) >>> column of the test set dataframe that contains the tokens to process.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "            a tuple contains the two feature matrix (training data and test data).\n",
    "        \"\"\"\n",
    "\n",
    "        if self.method == 'binary':\n",
    "            count_vectorizer = TfidfVectorizer(binary=True, use_idf=False, norm=None, max_features=60000)\n",
    "        elif self.method == 'tf':\n",
    "            count_vectorizer = TfidfVectorizer(use_idf=False, max_features=60000)\n",
    "        elif self.method == 'tf-idf':\n",
    "            count_vectorizer = TfidfVectorizer(max_features=60000)\n",
    "        else:\n",
    "            raise Exception(\"Invalid method. Use: binary, tf or tf-idf\")\n",
    "\n",
    "        transformed_train_data = count_vectorizer.fit_transform(train_data.apply(str))\n",
    "        transformed_test_data = count_vectorizer.transform(test_data.apply(str))\n",
    "\n",
    "        return transformed_train_data, transformed_test_data, count_vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning...\n",
      "Standardization...\n",
      "Tokenization...\n",
      "Removing stopwords...\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "# Use class to clean and tokenize sentences \n",
    "\n",
    "var=text_preprocessing()\n",
    "df=var.fit(df,'SMS')\n",
    "\n",
    "# I removed stopwords because they aren't usefull for the model (for\n",
    "# example \"the\", \"in\", \"a\"... there are many but they usually don't\n",
    "# give usefull informations if sentence is spam or no spam.)\n",
    "\n",
    "# Also I standardize sentences with remove special character, number\n",
    "# character, traform word to lower cases.\n",
    "\n",
    "# Tokenization is for trasform text to List."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESULT</th>\n",
       "      <th>SMS</th>\n",
       "      <th>tokens</th>\n",
       "      <th>SMS_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point  crazy   available only ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar    joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in   a wkly comp to win fa cup fina...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor    u c already then say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i don t think he goes to usf  he lives aro...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>freemsg hey there darling it s been   week s n...</td>\n",
       "      <td>[freemsg, hey, darling, week, word, back, like...</td>\n",
       "      <td>freemsg hey darling week word back like fun st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>even my brother is not like to speak with me  ...</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids...</td>\n",
       "      <td>even brother like speak treat like aids patent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>as per your request  melle melle  oru minnamin...</td>\n",
       "      <td>[per, request, melle, melle, oru, minnaminungi...</td>\n",
       "      <td>per request melle melle oru minnaminunginte nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>winner   as a valued network customer you have...</td>\n",
       "      <td>[winner, valued, network, customer, selected, ...</td>\n",
       "      <td>winner valued network customer selected receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>had your mobile    months or more  u r entitle...</td>\n",
       "      <td>[mobile, months, u, r, entitled, update, lates...</td>\n",
       "      <td>mobile months u r entitled update latest colou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>i m gonna be home soon and i don t want to tal...</td>\n",
       "      <td>[gonna, home, soon, want, talk, stuff, anymore...</td>\n",
       "      <td>gonna home soon want talk stuff anymore tonigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>six chances to win cash  from     to        po...</td>\n",
       "      <td>[six, chances, win, cash, pounds, txt, csh, se...</td>\n",
       "      <td>six chances win cash pounds txt csh send cost ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>urgent  you have won a   week free membership ...</td>\n",
       "      <td>[urgent, week, free, membership, prize, jackpo...</td>\n",
       "      <td>urgent week free membership prize jackpot txt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>i ve been searching for the right words to tha...</td>\n",
       "      <td>[searching, right, words, thank, breather, pro...</td>\n",
       "      <td>searching right words thank breather promise w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>i have a date on sunday with will</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>date sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>xxxmobilemovieclub  to use your credit  click ...</td>\n",
       "      <td>[xxxmobilemovieclub, use, credit, click, wap, ...</td>\n",
       "      <td>xxxmobilemovieclub use credit click wap link n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>oh k   i m watching here</td>\n",
       "      <td>[oh, k, watching]</td>\n",
       "      <td>oh k watching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>eh u remember how   spell his name    yes i di...</td>\n",
       "      <td>[eh, u, remember, spell, name, yes, v, naughty...</td>\n",
       "      <td>eh u remember spell name yes v naughty make v wet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>fine if that s the way u feel  that s the way ...</td>\n",
       "      <td>[fine, way, u, feel, way, gota, b]</td>\n",
       "      <td>fine way u feel way gota b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>england v macedonia   dont miss the goals team...</td>\n",
       "      <td>[england, v, macedonia, dont, miss, goals, tea...</td>\n",
       "      <td>england v macedonia dont miss goals team news ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>is that seriously how you spell his name</td>\n",
       "      <td>[seriously, spell, name]</td>\n",
       "      <td>seriously spell name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>i m going to try for   months ha ha only joking</td>\n",
       "      <td>[going, try, months, ha, ha, joking]</td>\n",
       "      <td>going try months ha ha joking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>so   pay first lar    then when is da stock co...</td>\n",
       "      <td>[pay, first, lar, da, stock, comin]</td>\n",
       "      <td>pay first lar da stock comin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>aft i finish my lunch then i go str down lor  ...</td>\n",
       "      <td>[aft, finish, lunch, go, str, lor, ard, smth, ...</td>\n",
       "      <td>aft finish lunch go str lor ard smth lor u fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>ffffffffff  alright no way i can meet up with ...</td>\n",
       "      <td>[ffffffffff, alright, way, meet, sooner]</td>\n",
       "      <td>ffffffffff alright way meet sooner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>just forced myself to eat a slice  i m really ...</td>\n",
       "      <td>[forced, eat, slice, really, hungry, tho, suck...</td>\n",
       "      <td>forced eat slice really hungry tho sucks mark ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>lol your always so convincing</td>\n",
       "      <td>[lol, always, convincing]</td>\n",
       "      <td>lol always convincing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>did you catch the bus   are you frying an egg ...</td>\n",
       "      <td>[catch, bus, frying, egg, make, tea, eating, m...</td>\n",
       "      <td>catch bus frying egg make tea eating mom left ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>i m back  amp  we re packing the car now  i ll...</td>\n",
       "      <td>[back, amp, packing, car, let, know, room]</td>\n",
       "      <td>back amp packing car let know room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>ahhh  work  i vaguely remember that  what does...</td>\n",
       "      <td>[ahhh, work, vaguely, remember, feel, like, lol]</td>\n",
       "      <td>ahhh work vaguely remember feel like lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5510</th>\n",
       "      <td>0</td>\n",
       "      <td>yeah it s jus rite</td>\n",
       "      <td>[yeah, jus, rite]</td>\n",
       "      <td>yeah jus rite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511</th>\n",
       "      <td>0</td>\n",
       "      <td>armand says get your ass over to epsilon</td>\n",
       "      <td>[armand, says, get, ass, epsilon]</td>\n",
       "      <td>armand says get ass epsilon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5512</th>\n",
       "      <td>0</td>\n",
       "      <td>u still havent got urself a jacket ah</td>\n",
       "      <td>[u, still, havent, got, urself, jacket, ah]</td>\n",
       "      <td>u still havent got urself jacket ah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>0</td>\n",
       "      <td>i m taking derek  amp  taylor to walmart  if i...</td>\n",
       "      <td>[taking, derek, amp, taylor, walmart, back, ti...</td>\n",
       "      <td>taking derek amp taylor walmart back time done...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>0</td>\n",
       "      <td>hi its in durban are you still on this number</td>\n",
       "      <td>[hi, durban, still, number]</td>\n",
       "      <td>hi durban still number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5515</th>\n",
       "      <td>0</td>\n",
       "      <td>ic  there are a lotta childporn cars then</td>\n",
       "      <td>[ic, lotta, childporn, cars]</td>\n",
       "      <td>ic lotta childporn cars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5516</th>\n",
       "      <td>0</td>\n",
       "      <td>no  i was trying it all weekend  v</td>\n",
       "      <td>[trying, weekend, v]</td>\n",
       "      <td>trying weekend v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517</th>\n",
       "      <td>0</td>\n",
       "      <td>you know  wot people wear  t shirts  jumpers  ...</td>\n",
       "      <td>[know, wot, people, wear, shirts, jumpers, hat...</td>\n",
       "      <td>know wot people wear shirts jumpers hat belt k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5518</th>\n",
       "      <td>0</td>\n",
       "      <td>cool  what time you think you can get here</td>\n",
       "      <td>[cool, time, think, get]</td>\n",
       "      <td>cool time think get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5519</th>\n",
       "      <td>0</td>\n",
       "      <td>wen did you get so spiritual and deep  that s ...</td>\n",
       "      <td>[wen, get, spiritual, deep, great]</td>\n",
       "      <td>wen get spiritual deep great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>0</td>\n",
       "      <td>have a safe trip to nigeria  wish you happines...</td>\n",
       "      <td>[safe, trip, nigeria, wish, happiness, soon, c...</td>\n",
       "      <td>safe trip nigeria wish happiness soon company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5521</th>\n",
       "      <td>0</td>\n",
       "      <td>hahaha  use your brain dear</td>\n",
       "      <td>[hahaha, use, brain, dear]</td>\n",
       "      <td>hahaha use brain dear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5522</th>\n",
       "      <td>0</td>\n",
       "      <td>well keep in mind i ve only got enough gas for...</td>\n",
       "      <td>[well, keep, mind, got, enough, gas, one, roun...</td>\n",
       "      <td>well keep mind got enough gas one round trip b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>0</td>\n",
       "      <td>yeh  indians was nice  tho it did kane me off ...</td>\n",
       "      <td>[yeh, indians, nice, tho, kane, bit, shud, go,...</td>\n",
       "      <td>yeh indians nice tho kane bit shud go drink so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5524</th>\n",
       "      <td>0</td>\n",
       "      <td>yes i have  so that s why u texted  pshew   mi...</td>\n",
       "      <td>[yes, u, texted, pshew, missing, much]</td>\n",
       "      <td>yes u texted pshew missing much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5525</th>\n",
       "      <td>0</td>\n",
       "      <td>no  i meant the calculation is the same  that ...</td>\n",
       "      <td>[meant, calculation, lt, gt, units, lt, gt, sc...</td>\n",
       "      <td>meant calculation lt gt units lt gt school rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5526</th>\n",
       "      <td>0</td>\n",
       "      <td>sorry  i ll call later</td>\n",
       "      <td>[sorry, call, later]</td>\n",
       "      <td>sorry call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5527</th>\n",
       "      <td>0</td>\n",
       "      <td>if you aren t here in the next   lt   gt   hou...</td>\n",
       "      <td>[next, lt, gt, hours, imma, flip, shit]</td>\n",
       "      <td>next lt gt hours imma flip shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5528</th>\n",
       "      <td>0</td>\n",
       "      <td>anything lor  juz both of us lor</td>\n",
       "      <td>[anything, lor, juz, us, lor]</td>\n",
       "      <td>anything lor juz us lor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>0</td>\n",
       "      <td>get me out of this dump heap  my mom decided t...</td>\n",
       "      <td>[get, dump, heap, mom, decided, come, lowes, b...</td>\n",
       "      <td>get dump heap mom decided come lowes boring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5530</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lor    sony ericsson salesman    i ask shuh...</td>\n",
       "      <td>[ok, lor, sony, ericsson, salesman, ask, shuhu...</td>\n",
       "      <td>ok lor sony ericsson salesman ask shuhui say q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531</th>\n",
       "      <td>0</td>\n",
       "      <td>ard   like dat lor</td>\n",
       "      <td>[ard, like, dat, lor]</td>\n",
       "      <td>ard like dat lor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5532</th>\n",
       "      <td>0</td>\n",
       "      <td>why don t you wait  til at least wednesday to ...</td>\n",
       "      <td>[wait, til, least, wednesday, see, get]</td>\n",
       "      <td>wait til least wednesday see get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5533</th>\n",
       "      <td>0</td>\n",
       "      <td>huh y lei</td>\n",
       "      <td>[huh, lei]</td>\n",
       "      <td>huh lei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5534</th>\n",
       "      <td>1</td>\n",
       "      <td>reminder from o   to get      pounds free call...</td>\n",
       "      <td>[reminder, get, pounds, free, call, credit, de...</td>\n",
       "      <td>reminder get pounds free call credit details g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>1</td>\n",
       "      <td>this is the  nd time we have tried   contact u...</td>\n",
       "      <td>[nd, time, tried, contact, u, u, pound, prize,...</td>\n",
       "      <td>nd time tried contact u u pound prize claim ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>0</td>\n",
       "      <td>will   b going to esplanade fr home</td>\n",
       "      <td>[b, going, esplanade, fr, home]</td>\n",
       "      <td>b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>0</td>\n",
       "      <td>pity    was in mood for that  so   any other s...</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "      <td>pity mood suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>0</td>\n",
       "      <td>the guy did some bitching but i acted like i d...</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "      <td>guy bitching acted like interested buying some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>0</td>\n",
       "      <td>rofl  its true to its name</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5540 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RESULT                                                SMS  \\\n",
       "0          0  go until jurong point  crazy   available only ...   \n",
       "1          0                      ok lar    joking wif u oni      \n",
       "2          1  free entry in   a wkly comp to win fa cup fina...   \n",
       "3          0  u dun say so early hor    u c already then say      \n",
       "4          0  nah i don t think he goes to usf  he lives aro...   \n",
       "5          1  freemsg hey there darling it s been   week s n...   \n",
       "6          0  even my brother is not like to speak with me  ...   \n",
       "7          0  as per your request  melle melle  oru minnamin...   \n",
       "8          1  winner   as a valued network customer you have...   \n",
       "9          1  had your mobile    months or more  u r entitle...   \n",
       "10         0  i m gonna be home soon and i don t want to tal...   \n",
       "11         1  six chances to win cash  from     to        po...   \n",
       "12         1  urgent  you have won a   week free membership ...   \n",
       "13         0  i ve been searching for the right words to tha...   \n",
       "14         0                i have a date on sunday with will     \n",
       "15         1  xxxmobilemovieclub  to use your credit  click ...   \n",
       "16         0                         oh k   i m watching here     \n",
       "17         0  eh u remember how   spell his name    yes i di...   \n",
       "18         0  fine if that s the way u feel  that s the way ...   \n",
       "19         1  england v macedonia   dont miss the goals team...   \n",
       "20         0          is that seriously how you spell his name    \n",
       "21         0    i m going to try for   months ha ha only joking   \n",
       "22         0  so   pay first lar    then when is da stock co...   \n",
       "23         0  aft i finish my lunch then i go str down lor  ...   \n",
       "24         0  ffffffffff  alright no way i can meet up with ...   \n",
       "25         0  just forced myself to eat a slice  i m really ...   \n",
       "26         0                     lol your always so convincing    \n",
       "27         0  did you catch the bus   are you frying an egg ...   \n",
       "28         0  i m back  amp  we re packing the car now  i ll...   \n",
       "29         0  ahhh  work  i vaguely remember that  what does...   \n",
       "...      ...                                                ...   \n",
       "5510       0                              yeah it s jus rite      \n",
       "5511       0           armand says get your ass over to epsilon   \n",
       "5512       0             u still havent got urself a jacket ah    \n",
       "5513       0  i m taking derek  amp  taylor to walmart  if i...   \n",
       "5514       0      hi its in durban are you still on this number   \n",
       "5515       0         ic  there are a lotta childporn cars then    \n",
       "5516       0                 no  i was trying it all weekend  v   \n",
       "5517       0  you know  wot people wear  t shirts  jumpers  ...   \n",
       "5518       0        cool  what time you think you can get here    \n",
       "5519       0  wen did you get so spiritual and deep  that s ...   \n",
       "5520       0  have a safe trip to nigeria  wish you happines...   \n",
       "5521       0                        hahaha  use your brain dear   \n",
       "5522       0  well keep in mind i ve only got enough gas for...   \n",
       "5523       0  yeh  indians was nice  tho it did kane me off ...   \n",
       "5524       0  yes i have  so that s why u texted  pshew   mi...   \n",
       "5525       0  no  i meant the calculation is the same  that ...   \n",
       "5526       0                             sorry  i ll call later   \n",
       "5527       0  if you aren t here in the next   lt   gt   hou...   \n",
       "5528       0                  anything lor  juz both of us lor    \n",
       "5529       0  get me out of this dump heap  my mom decided t...   \n",
       "5530       0  ok lor    sony ericsson salesman    i ask shuh...   \n",
       "5531       0                                ard   like dat lor    \n",
       "5532       0  why don t you wait  til at least wednesday to ...   \n",
       "5533       0                                       huh y lei      \n",
       "5534       1  reminder from o   to get      pounds free call...   \n",
       "5535       1  this is the  nd time we have tried   contact u...   \n",
       "5536       0               will   b going to esplanade fr home    \n",
       "5537       0  pity    was in mood for that  so   any other s...   \n",
       "5538       0  the guy did some bitching but i acted like i d...   \n",
       "5539       0                         rofl  its true to its name   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, wkly, comp, win, fa, cup, final,...   \n",
       "3         [u, dun, say, early, hor, u, c, already, say]   \n",
       "4        [nah, think, goes, usf, lives, around, though]   \n",
       "5     [freemsg, hey, darling, week, word, back, like...   \n",
       "6     [even, brother, like, speak, treat, like, aids...   \n",
       "7     [per, request, melle, melle, oru, minnaminungi...   \n",
       "8     [winner, valued, network, customer, selected, ...   \n",
       "9     [mobile, months, u, r, entitled, update, lates...   \n",
       "10    [gonna, home, soon, want, talk, stuff, anymore...   \n",
       "11    [six, chances, win, cash, pounds, txt, csh, se...   \n",
       "12    [urgent, week, free, membership, prize, jackpo...   \n",
       "13    [searching, right, words, thank, breather, pro...   \n",
       "14                                       [date, sunday]   \n",
       "15    [xxxmobilemovieclub, use, credit, click, wap, ...   \n",
       "16                                    [oh, k, watching]   \n",
       "17    [eh, u, remember, spell, name, yes, v, naughty...   \n",
       "18                   [fine, way, u, feel, way, gota, b]   \n",
       "19    [england, v, macedonia, dont, miss, goals, tea...   \n",
       "20                             [seriously, spell, name]   \n",
       "21                 [going, try, months, ha, ha, joking]   \n",
       "22                  [pay, first, lar, da, stock, comin]   \n",
       "23    [aft, finish, lunch, go, str, lor, ard, smth, ...   \n",
       "24             [ffffffffff, alright, way, meet, sooner]   \n",
       "25    [forced, eat, slice, really, hungry, tho, suck...   \n",
       "26                            [lol, always, convincing]   \n",
       "27    [catch, bus, frying, egg, make, tea, eating, m...   \n",
       "28           [back, amp, packing, car, let, know, room]   \n",
       "29     [ahhh, work, vaguely, remember, feel, like, lol]   \n",
       "...                                                 ...   \n",
       "5510                                  [yeah, jus, rite]   \n",
       "5511                  [armand, says, get, ass, epsilon]   \n",
       "5512        [u, still, havent, got, urself, jacket, ah]   \n",
       "5513  [taking, derek, amp, taylor, walmart, back, ti...   \n",
       "5514                        [hi, durban, still, number]   \n",
       "5515                       [ic, lotta, childporn, cars]   \n",
       "5516                               [trying, weekend, v]   \n",
       "5517  [know, wot, people, wear, shirts, jumpers, hat...   \n",
       "5518                           [cool, time, think, get]   \n",
       "5519                 [wen, get, spiritual, deep, great]   \n",
       "5520  [safe, trip, nigeria, wish, happiness, soon, c...   \n",
       "5521                         [hahaha, use, brain, dear]   \n",
       "5522  [well, keep, mind, got, enough, gas, one, roun...   \n",
       "5523  [yeh, indians, nice, tho, kane, bit, shud, go,...   \n",
       "5524             [yes, u, texted, pshew, missing, much]   \n",
       "5525  [meant, calculation, lt, gt, units, lt, gt, sc...   \n",
       "5526                               [sorry, call, later]   \n",
       "5527            [next, lt, gt, hours, imma, flip, shit]   \n",
       "5528                      [anything, lor, juz, us, lor]   \n",
       "5529  [get, dump, heap, mom, decided, come, lowes, b...   \n",
       "5530  [ok, lor, sony, ericsson, salesman, ask, shuhu...   \n",
       "5531                              [ard, like, dat, lor]   \n",
       "5532            [wait, til, least, wednesday, see, get]   \n",
       "5533                                         [huh, lei]   \n",
       "5534  [reminder, get, pounds, free, call, credit, de...   \n",
       "5535  [nd, time, tried, contact, u, u, pound, prize,...   \n",
       "5536                    [b, going, esplanade, fr, home]   \n",
       "5537                          [pity, mood, suggestions]   \n",
       "5538  [guy, bitching, acted, like, interested, buyin...   \n",
       "5539                                 [rofl, true, name]   \n",
       "\n",
       "                                                  SMS_R  \n",
       "0     go jurong point crazy available bugis n great ...  \n",
       "1                               ok lar joking wif u oni  \n",
       "2     free entry wkly comp win fa cup final tkts st ...  \n",
       "3                   u dun say early hor u c already say  \n",
       "4                nah think goes usf lives around though  \n",
       "5     freemsg hey darling week word back like fun st...  \n",
       "6        even brother like speak treat like aids patent  \n",
       "7     per request melle melle oru minnaminunginte nu...  \n",
       "8     winner valued network customer selected receiv...  \n",
       "9     mobile months u r entitled update latest colou...  \n",
       "10    gonna home soon want talk stuff anymore tonigh...  \n",
       "11    six chances win cash pounds txt csh send cost ...  \n",
       "12    urgent week free membership prize jackpot txt ...  \n",
       "13    searching right words thank breather promise w...  \n",
       "14                                          date sunday  \n",
       "15    xxxmobilemovieclub use credit click wap link n...  \n",
       "16                                        oh k watching  \n",
       "17    eh u remember spell name yes v naughty make v wet  \n",
       "18                           fine way u feel way gota b  \n",
       "19    england v macedonia dont miss goals team news ...  \n",
       "20                                 seriously spell name  \n",
       "21                        going try months ha ha joking  \n",
       "22                         pay first lar da stock comin  \n",
       "23    aft finish lunch go str lor ard smth lor u fin...  \n",
       "24                   ffffffffff alright way meet sooner  \n",
       "25    forced eat slice really hungry tho sucks mark ...  \n",
       "26                                lol always convincing  \n",
       "27    catch bus frying egg make tea eating mom left ...  \n",
       "28                   back amp packing car let know room  \n",
       "29             ahhh work vaguely remember feel like lol  \n",
       "...                                                 ...  \n",
       "5510                                      yeah jus rite  \n",
       "5511                        armand says get ass epsilon  \n",
       "5512                u still havent got urself jacket ah  \n",
       "5513  taking derek amp taylor walmart back time done...  \n",
       "5514                             hi durban still number  \n",
       "5515                            ic lotta childporn cars  \n",
       "5516                                   trying weekend v  \n",
       "5517  know wot people wear shirts jumpers hat belt k...  \n",
       "5518                                cool time think get  \n",
       "5519                       wen get spiritual deep great  \n",
       "5520  safe trip nigeria wish happiness soon company ...  \n",
       "5521                              hahaha use brain dear  \n",
       "5522  well keep mind got enough gas one round trip b...  \n",
       "5523  yeh indians nice tho kane bit shud go drink so...  \n",
       "5524                    yes u texted pshew missing much  \n",
       "5525  meant calculation lt gt units lt gt school rea...  \n",
       "5526                                   sorry call later  \n",
       "5527                    next lt gt hours imma flip shit  \n",
       "5528                            anything lor juz us lor  \n",
       "5529        get dump heap mom decided come lowes boring  \n",
       "5530  ok lor sony ericsson salesman ask shuhui say q...  \n",
       "5531                                   ard like dat lor  \n",
       "5532                   wait til least wednesday see get  \n",
       "5533                                            huh lei  \n",
       "5534  reminder get pounds free call credit details g...  \n",
       "5535  nd time tried contact u u pound prize claim ea...  \n",
       "5536                          b going esplanade fr home  \n",
       "5537                              pity mood suggestions  \n",
       "5538  guy bitching acted like interested buying some...  \n",
       "5539                                     rofl true name  \n",
       "\n",
       "[5540 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function for convert a list to words to a Sentence\n",
    "def detokenizer(x): return \" \".join(x)\n",
    "\n",
    "df['SMS_R']=df['tokens'].apply(detokenizer) \n",
    "\n",
    "# For Neural Network I need a numeric target variable\n",
    "\n",
    "def class_to_number(x):\n",
    "    if x=='ham':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "df['RESULT']=df['RESULT'].apply(class_to_number)\n",
    "\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                75650     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 75,661\n",
      "Trainable params: 75,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Training Accuracy: 0.9995\n",
      "Testing Accuracy:  0.9841\n",
      "1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 10)                75650     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 75,661\n",
      "Trainable params: 75,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training Accuracy: 0.9995\n",
      "Testing Accuracy:  0.9812\n",
      "2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 10)                75650     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 75,661\n",
      "Trainable params: 75,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training Accuracy: 0.9998\n",
      "Testing Accuracy:  0.9841\n",
      "3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 10)                75650     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 75,661\n",
      "Trainable params: 75,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy:  0.9819\n",
      "4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 10)                75650     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 75,661\n",
      "Trainable params: 75,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy:  0.9812\n",
      "5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 10)                75650     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 75,661\n",
      "Trainable params: 75,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy:  0.9798\n",
      "6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 10)                75650     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 75,661\n",
      "Trainable params: 75,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training Accuracy: 0.9993\n",
      "Testing Accuracy:  0.9834\n",
      "7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 10)                75650     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 75,661\n",
      "Trainable params: 75,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training Accuracy: 0.9990\n",
      "Testing Accuracy:  0.9834\n",
      "8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 10)                75650     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 75,661\n",
      "Trainable params: 75,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training Accuracy: 0.9995\n",
      "Testing Accuracy:  0.9841\n",
      "9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 10)                75650     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 75,661\n",
      "Trainable params: 75,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9995\n",
      "Testing Accuracy:  0.9834\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# take sentences and target variable\n",
    "sentences = df['SMS_R'].values\n",
    "y = df['RESULT'].values\n",
    "\n",
    "\n",
    "# I used a CountVectorizer that trasform for each word in sentence \"s\"\n",
    "# to couple (word, #word_in_s). These vectorizer is necessary because\n",
    "# for neural network we need a numberic input. There are other\n",
    "# techniques for this, like term frequeny - Inverse document Frequency\n",
    "# that is better because consider firstly relative frequency instead\n",
    "# of absolute frequency and after put a weight inverse proportional\n",
    "# of frequency of a word.\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences)\n",
    "\n",
    "accuracy_list=[]        #cross validation\n",
    "for k in range(0,10):\n",
    "    print(k)\n",
    "    \n",
    "    # split dataset of sentences in train and test\n",
    "    \n",
    "    sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
    "    sentences, y, test_size=0.25, random_state=1000) \n",
    "    X_train = vectorizer.transform(sentences_train)\n",
    "    X_test  = vectorizer.transform(sentences_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Use a simple Deep Learning Architecture with a \"relu\" activation\n",
    "    # function in first layer and a activation \"sigmoid\" for last.\n",
    "    # I used DropOut for evade overfitting.\n",
    "    \n",
    "    input_dim = X_train.shape[1]  # Number of features\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "    model.add(layers.Dropout(0.60))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    #optimizer adam and a loss function for a classification proble\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                   metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    #100 epoches\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=100,\n",
    "                         verbose=False,\n",
    "                         validation_data=(X_test, y_test),\n",
    "                         batch_size=10)\n",
    "\n",
    "    loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "    print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "    print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "    accuracy_list.append(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_accuracy: 0.9826714801874401 +- 0.0014440433212996263\n"
     ]
    }
   ],
   "source": [
    "# cross validation accuracy\n",
    "\n",
    "print(\"cv_accuracy: \"+str(np.array(accuracy_list).mean())+\" +- \"+str(np.array(accuracy_list).std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning...\n",
      "Standardization...\n",
      "Tokenization...\n",
      "Removing stopwords...\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "var=text_preprocessing()\n",
    "unlabeled=var.fit(unlabeled,'SMS')\n",
    "unlabeled['SMS_R']=unlabeled['tokens'].apply(detokenizer)\n",
    "sentences = unlabeled['SMS_R'].values\n",
    "y = unlabeled['RESULT'].values\n",
    "X= vectorizer.transform(sentences)\n",
    "\n",
    "unlabeled['RESULT_pred']=model.predict(X).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95      spam\n",
       "124      ham\n",
       "347      ham\n",
       "567      ham\n",
       "598     spam\n",
       "733      ham\n",
       "940      ham\n",
       "1099     ham\n",
       "1154     ham\n",
       "1349     ham\n",
       "1531     ham\n",
       "1724     ham\n",
       "1920     ham\n",
       "1965     ham\n",
       "2186     ham\n",
       "2413    spam\n",
       "2435     ham\n",
       "2820     ham\n",
       "3107     ham\n",
       "3407     ham\n",
       "3637     ham\n",
       "3799     ham\n",
       "3824     ham\n",
       "3841     ham\n",
       "4047    spam\n",
       "4211     ham\n",
       "4240     ham\n",
       "4529     ham\n",
       "5050     ham\n",
       "5236     ham\n",
       "5365    spam\n",
       "5547    spam\n",
       "Name: RESULT, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled=pd.DataFrame(unlabeled['RESULT_pred'])\n",
    "def number_to_class(x):\n",
    "    if x==0:\n",
    "        return 'ham'\n",
    "    else:\n",
    "        return 'spam'\n",
    "    \n",
    "unlabeled['RESULT']=unlabeled['RESULT_pred'].apply(number_to_class)\n",
    "unlabeled['RESULT'].to_csv('NLP.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
